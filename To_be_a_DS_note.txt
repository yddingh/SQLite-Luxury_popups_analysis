
BI Engineer / Analytics Engineer
定位与价值
负责把业务数据「产品化」：搭建 DWH、写 dbt 模型、做数据测试、产出给 BI 的干净表；桥接 Data Engineer 与 Data Analyst。
备注：你贴的 GA technologies JD 就是这种

日常工作
编写/维护 dbt models & SQL（30%）
监控 ETL/ELT pipeline（trocco/Airflow 等）（20%）
支持 BI 团队的指标、进行数据建模（30%）
写文档、维护数据字典（20%）

技术栈：SQL（高级）、dbt（或类似）、数据建模（星型/雪花）、DWH（Snowflake / BigQuery / Redshift）、基础 Python 脚本
加分：Airflow、CI/CD、数据质量监控、版本控制 (Git)、Tableau/Looker

面试常考点
SQL + dbt 实际题（让你写 model 或优化 SQL）
数据建模题（给业务场景设计 fact/dim 表）
Pipeline 故障排查/架构题（如何保证数据质量）
代码 review / Git 流程经验

简历/项目能展示的成果
用 dbt 做的模型仓库（带 tests）+ demo 仪表盘
数据质量检测规则 & 恢复流程文档
案例：把一个“零散报表”改造成复用表并减少 N 条 SQL

具体下一步（最短路径）
1. SQL 强化 + 学 dbt（模仿开源教程，做本地示例）。
2. 在 Kaggle 或公开数据上建立小型仓库（用 BigQuery Free 或本地 Postgres + dbt），输出一个 Tableau 仪表盘。
3. 在简历上把“写脚本、维护流水线”的经验表述为“实现 ETL 自动化 & 建模，降低报表制作时间 X%”。


Data Scientist (DS)

定位：业务/产品侧的分析驱动，利用统计与机器学习解决业务决策问题（预测、分群、因果推断、A/B 分析），强调从数据得出能落地的洞察与模型。

内容：需求分析、A/B测试、预测建模、业务指标优化
日常工作
数据探索、特征工程（40%）
建模型/验证（30%）
与业务沟通 & 把结果产出为可执行建议（20%）
维护模型（小规模）或协作把模型交付给 MLE（10%）

技术栈
必备：Python（pandas, scikit-learn），SQL，统计学基础（假设检验、置信区间、A/B 测试）
加分：深度学习 (PyTorch)、时间序列、因果推断、AutoML、实验设计

面试常考点
ML 项目问答：特征工程、过拟合处理、模型选择、评估指标
给业务问题提出可行数据方案（case）
代码 take-home 或 whiteboard（实现一个简单模型或写数据处理脚本）
简历/项目能展示的成果
一个端到端建模项目（数据 → 特征 → 模型 → 评估 → 业务价值）
清晰的 metric 定义和提升量化（例如提升预测准确率、降低流失率 X%）

具体下一步（最短路径）
1. 做一个端到端业务项目（最好与不动产/你感兴趣的行业相关）：用真实或公开数据做预测（价格/成交概率），并写出业务影响分析。
2. 补统计学基础（A/B、p-value、置信区间、偏差-方差）。
3. 熟练解释模型结果（特征重要性、模型局限、如何落地）。
4. 在面试中突显“用数据解决业务问题”的案例讲述能力。


Data Analyst (DA)
定位与价值
业务侧的“数据翻译官”：把数据变成业务洞察、KPI 报表、可操作建议，往往直接支持业务线（市场、销售、运营）。写 SQL、做 Tableau/Looker dashboard、整理 PPT、解释 KPI

日常工作
拉 SQL 报表、做 ad-hoc 分析（60%）
用 Tableau/Looker/Excel 做可视化仪表盘（20%）
写 PPT / 给业务做汇报、需求沟通（20%）

必备：SQL（强）、Excel/Spreadsheet、Tableau / Looker / Power BI、基础 Python＋Pandas（用于数据清洗）
加分：GA4、BigQuery、基本统计知识、SQL 窗口函数、基础可视化审美
软技能：会和业务部门打交道，沟通能力

面试常考点 / 题型
SQL/数据提取题（现场写 SQL）
业务 case（给一个场景问你如何衡量 KPI）
Dashboard 设计题（如何展示转化漏斗）
行为面试：沟通、讲故事能力
简历/项目能展示的成果
某 KPI 的月度报表自动化（用 SQL + Tableau）
通过某分析给出建议并带来 XX% 改善（即使是模拟数据也可量化）
清晰的 Dashboard 链接或截图 + 指标定义文档

具体下一步（最短路径）
1. 强化 SQL（写 window function、复杂 JOIN、CTE）。
2. 学 Tableau（做 2 个业务仪表盘，公开展示）。
3. 完成 1 个端到端项目：数据源 → SQL 清洗 → Tableau 仪表盘 → PPT 结论。
4. 简历上把 SDE 的“自动化/脚本/数据采集”等工程工作写成“提高效率 / 自动化报表”的句式。





----------------------------------------------------------------
SQL 和数据库管理软件
DBeaver
●建立db连接
●创建新表/列/行，填充数据

----------------------------------------------------------------
ETL/ELT pipeline（trocco, dbt, Python）
（Extract → Transform → Load）
自动化工具，用来洗数据的。

----------------------------------------------------------------
dbt(data build tool)：专门做数据转换/建模的工具，把 SQL 脚本工程化、模块化。
●安装SQLite的 dbt-core 和适配器
	pip install dbt-core dbt-sqlite
●创建 dbt 项目
	dbt init xxxx(name)
●配置db
	\.dbt\profiles.yml
	◎dev：开发环境，通常本地调试用
	◎prod：生产环境，通常部署在公司服务器或云端
	改database/schemas_and_paths/schema_directory
	SQLite只有一个主 schema，dbt 内部默认叫 main，是默认输出端口
	链接地址现在是本地，如果是正式工作一般数据库在云端
●新建模型 SQL 文件
	cd models
	type nul>yyyyy.sql
	撰写sql模型，一般只能select，拉取部分数据到本地后续分析
●进入目标文件夹，运行 dbt 命令
	dbt run -s yyyyy
●看结果
	结果在\xxxx\data\yyyyy.db
	DBeaver链接到目标地址，查看内容
	必须用sql语句查询，不能依赖Dbeaver的可视化窗口

----------------------------------------------------------------
Github
●检查本地是否有密钥
	Get-ChildItem ~/.ssh
●没有的话生成密钥
	ssh-keygen -t ed25519 -C yangdian7777@gmail.com
●复制密钥
	cat ~/.ssh/id_ed25519.pub
●打开 GitHub → 右上角头像 → Settings → SSH and GPG keys → New SSH key
●检查连接
	ssh -T git@github.com
●拉取远程文件到本地
	git pull origin main
●本地改动提交
	git add .
	git commit -m "message"
	git push origin main
●其他指令
    排查状态
	git status
    查看分支
	git branch
    修改用于提交的用户名和邮箱
	git config --global user.name "Your Name"
	git config --global user.email you@example.com




----------------------------------------------------------------
DWH（Data Warehouse，数据仓库）以及数据管理的设计建模

----------------------------------------------------------------
BI 工具（Tableau, Looker Studio） 
面向业务方的可视化与报表。做DASHBOARD的

----------------------------------------------------------------
AWS/GCP → 基础设施层面（S3、BigQuery、Cloud Storage 等）。



●对数据进行整理，打印每一列内容，看其数据类型，罗列所有值的数量
●定位目标值
●清理缺失数据，根据内容推测，填充不一样的值进去。（众数，中位数，0或1等）或者不相干的就删除（真的可能完全不相关吗？）
●定义特征类型，类别转换
●细分特征

●跑模型
　建模目标变量是连续还是分类？
　◎回归问题（Regression）：预测一个连续的数值。例如销售额、气温、房价等。
　◎分类问题（Classification）：做出判断。例如判断顾客是否会流失（是/否）、识别图片是猫还是狗。

·构建数据集
·设置参数
·训练模型（带早停）
·验证评估（RMSE / RMSLE）
·测试集预测
·生成提交文件

机器学习
第1节 数据清洗
第2节 回归 8.5h（1周）
第3节 分类算法 6.5h
第10节 模型 2.5h（1周）
第4-9节 备选

统计
python
数据可视化
数据库与SQL


查看唯一值及其频数
test['store_nbr'].value_counts(dropna=False)
